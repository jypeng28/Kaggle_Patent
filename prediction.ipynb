{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c96e4d",
   "metadata": {
    "papermill": {
     "duration": 0.046007,
     "end_time": "2022-06-16T03:23:28.984649",
     "exception": false,
     "start_time": "2022-06-16T03:23:28.938642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ensemble of the three notebooks.Please upvote the original notebooks:\n",
    "\n",
    "**1. Deberta v3 large**\n",
    "[PPPM / Deberta-v3-large baseline [inference]](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n",
    "\n",
    "**2. Roberta-large**\n",
    "[PatentPhrase RoBERTa Inference](https://www.kaggle.com/code/santhoshkumarv/patentphrase-roberta-inference-lb-0-814)\n",
    "\n",
    "**3. Bert-for-papent**\n",
    "\n",
    "And use ensemble strategy from:\n",
    "[Tips for ensambling](https://www.kaggle.com/code/jellyz9/tips-for-ensambling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639e335",
   "metadata": {
    "papermill": {
     "duration": 0.041559,
     "end_time": "2022-06-16T03:23:29.068256",
     "exception": false,
     "start_time": "2022-06-16T03:23:29.026697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.Deberta v3 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d1fb1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:23:29.194553Z",
     "iopub.status.busy": "2022-06-16T03:23:29.194155Z",
     "iopub.status.idle": "2022-06-16T03:23:29.205908Z",
     "shell.execute_reply": "2022-06-16T03:23:29.205208Z"
    },
    "papermill": {
     "duration": 0.06527,
     "end_time": "2022-06-16T03:23:29.208004",
     "exception": false,
     "start_time": "2022-06-16T03:23:29.142734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f9e608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:23:29.294804Z",
     "iopub.status.busy": "2022-06-16T03:23:29.294161Z",
     "iopub.status.idle": "2022-06-16T03:23:29.299322Z",
     "shell.execute_reply": "2022-06-16T03:23:29.298563Z"
    },
    "papermill": {
     "duration": 0.050195,
     "end_time": "2022-06-16T03:23:29.300969",
     "exception": false,
     "start_time": "2022-06-16T03:23:29.250774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    num_workers=4\n",
    "    path=\"../input/finetunedebertaadver/baseline_adv/Baseline_adv/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=175\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4a8ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:23:29.388351Z",
     "iopub.status.busy": "2022-06-16T03:23:29.387638Z",
     "iopub.status.idle": "2022-06-16T03:24:01.512440Z",
     "shell.execute_reply": "2022-06-16T03:24:01.511684Z"
    },
    "papermill": {
     "duration": 32.21945,
     "end_time": "2022-06-16T03:24:01.561989",
     "exception": false,
     "start_time": "2022-06-16T03:23:29.342539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.18.0\n",
      "Uninstalling transformers-4.18.0:\n",
      "  Successfully uninstalled transformers-4.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tokenizers 0.12.1\n",
      "Uninstalling tokenizers-0.12.1:\n",
      "  Successfully uninstalled tokenizers-0.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/pppm-pip-wheels-dataset\n",
      "Processing /kaggle/input/pppm-pip-wheels-dataset/transformers-4.16.2-py3-none-any.whl\n",
      "Processing /kaggle/input/pppm-pip-wheels-dataset/tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.11.6 transformers-4.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/pppm-pip-wheels-dataset\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.7/site-packages (0.11.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('pip uninstall -y tokenizers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399d94a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:01.659813Z",
     "iopub.status.busy": "2022-06-16T03:24:01.659551Z",
     "iopub.status.idle": "2022-06-16T03:24:01.670709Z",
     "shell.execute_reply": "2022-06-16T03:24:01.669933Z"
    },
    "papermill": {
     "duration": 0.062333,
     "end_time": "2022-06-16T03:24:01.672775",
     "exception": false,
     "start_time": "2022-06-16T03:24:01.610442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042feb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:01.775369Z",
     "iopub.status.busy": "2022-06-16T03:24:01.775097Z",
     "iopub.status.idle": "2022-06-16T03:24:01.810796Z",
     "shell.execute_reply": "2022-06-16T03:24:01.809949Z"
    },
    "papermill": {
     "duration": 0.08802,
     "end_time": "2022-06-16T03:24:01.812721",
     "exception": false,
     "start_time": "2022-06-16T03:24:01.724701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape: (36, 4)\n",
      "submission.shape: (36, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target context\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n",
       "2  36baf228038e314b      lower trunnion                 lower locating     B60\n",
       "3  1f37ead645e7f0c8       cap component                  upper portion     D06\n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  score\n",
       "0  4112d61851461f60      0\n",
       "1  09e418c93a776564      0\n",
       "2  36baf228038e314b      0\n",
       "3  1f37ead645e7f0c8      0\n",
       "4  71a5b6ad068d531f      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "print(f\"test.shape: {test.shape}\")\n",
    "print(f\"submission.shape: {submission.shape}\")\n",
    "display(test.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56fd45d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:01.912048Z",
     "iopub.status.busy": "2022-06-16T03:24:01.911787Z",
     "iopub.status.idle": "2022-06-16T03:24:01.957909Z",
     "shell.execute_reply": "2022-06-16T03:24:01.957147Z"
    },
    "papermill": {
     "duration": 0.097891,
     "end_time": "2022-06-16T03:24:01.959764",
     "exception": false,
     "start_time": "2022-06-16T03:24:01.861873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "      <td>PHYSICS. OPTICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target  \\\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
       "2  36baf228038e314b      lower trunnion                 lower locating   \n",
       "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
       "\n",
       "  context                                       context_text  \n",
       "0     G02                                    PHYSICS. OPTICS  \n",
       "1     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...  \n",
       "2     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...  \n",
       "3     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...  \n",
       "4     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CPC Data\n",
    "# ====================================================\n",
    "cpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\n",
    "test['context_text'] = test['context'].map(cpc_texts)\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a433cfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:02.060298Z",
     "iopub.status.busy": "2022-06-16T03:24:02.059719Z",
     "iopub.status.idle": "2022-06-16T03:24:02.072290Z",
     "shell.execute_reply": "2022-06-16T03:24:02.071543Z"
    },
    "papermill": {
     "duration": 0.066477,
     "end_time": "2022-06-16T03:24:02.074932",
     "exception": false,
     "start_time": "2022-06-16T03:24:02.008455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "      <td>PHYSICS. OPTICS</td>\n",
       "      <td>opc drum[SEP]inorganic photoconductor drum[SEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>adjust gas flow[SEP]altering gas flow[SEP]MECH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n",
       "      <td>lower trunnion[SEP]lower locating[SEP]PERFORMI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n",
       "      <td>cap component[SEP]upper portion[SEP]TEXTILES; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n",
       "      <td>neural stimulation[SEP]artificial neural netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target  \\\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
       "2  36baf228038e314b      lower trunnion                 lower locating   \n",
       "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
       "\n",
       "  context                                       context_text  \\\n",
       "0     G02                                    PHYSICS. OPTICS   \n",
       "1     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "2     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...   \n",
       "3     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...   \n",
       "4     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE   \n",
       "\n",
       "                                                text  \n",
       "0  opc drum[SEP]inorganic photoconductor drum[SEP...  \n",
       "1  adjust gas flow[SEP]altering gas flow[SEP]MECH...  \n",
       "2  lower trunnion[SEP]lower locating[SEP]PERFORMI...  \n",
       "3  cap component[SEP]upper portion[SEP]TEXTILES; ...  \n",
       "4  neural stimulation[SEP]artificial neural netwo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d747a171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:02.181835Z",
     "iopub.status.busy": "2022-06-16T03:24:02.180946Z",
     "iopub.status.idle": "2022-06-16T03:24:02.958902Z",
     "shell.execute_reply": "2022-06-16T03:24:02.958124Z"
    },
    "papermill": {
     "duration": 0.835491,
     "end_time": "2022-06-16T03:24:02.961266",
     "exception": false,
     "start_time": "2022-06-16T03:24:02.125775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8a5aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:03.064045Z",
     "iopub.status.busy": "2022-06-16T03:24:03.063485Z",
     "iopub.status.idle": "2022-06-16T03:24:03.073130Z",
     "shell.execute_reply": "2022-06-16T03:24:03.072313Z"
    },
    "papermill": {
     "duration": 0.062894,
     "end_time": "2022-06-16T03:24:03.075248",
     "exception": false,
     "start_time": "2022-06-16T03:24:03.012354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text,\n",
    "                           add_special_tokens=True,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04e17f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:03.176108Z",
     "iopub.status.busy": "2022-06-16T03:24:03.175819Z",
     "iopub.status.idle": "2022-06-16T03:24:03.191107Z",
     "shell.execute_reply": "2022-06-16T03:24:03.190392Z"
    },
    "papermill": {
     "duration": 0.068604,
     "end_time": "2022-06-16T03:24:03.193191",
     "exception": false,
     "start_time": "2022-06-16T03:24:03.124587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c09f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:03.293946Z",
     "iopub.status.busy": "2022-06-16T03:24:03.293482Z",
     "iopub.status.idle": "2022-06-16T03:24:03.299674Z",
     "shell.execute_reply": "2022-06-16T03:24:03.298936Z"
    },
    "papermill": {
     "duration": 0.059076,
     "end_time": "2022-06-16T03:24:03.301383",
     "exception": false,
     "start_time": "2022-06-16T03:24:03.242307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea89e69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:24:03.409151Z",
     "iopub.status.busy": "2022-06-16T03:24:03.408071Z",
     "iopub.status.idle": "2022-06-16T03:26:18.968962Z",
     "shell.execute_reply": "2022-06-16T03:26:18.967461Z"
    },
    "papermill": {
     "duration": 135.620641,
     "end_time": "2022-06-16T03:26:18.970958",
     "exception": false,
     "start_time": "2022-06-16T03:24:03.350317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred1 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3797c9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:26:19.085909Z",
     "iopub.status.busy": "2022-06-16T03:26:19.085206Z",
     "iopub.status.idle": "2022-06-16T03:28:35.355718Z",
     "shell.execute_reply": "2022-06-16T03:28:35.354807Z"
    },
    "papermill": {
     "duration": 136.33024,
     "end_time": "2022-06-16T03:28:35.358384",
     "exception": false,
     "start_time": "2022-06-16T03:26:19.028144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "CFG.path = \"../input/debertav3large/\"\n",
    "CFG.config_path = CFG.path+'config.pth'\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred6 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ff1a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:28:35.488506Z",
     "iopub.status.busy": "2022-06-16T03:28:35.488173Z",
     "iopub.status.idle": "2022-06-16T03:29:40.149621Z",
     "shell.execute_reply": "2022-06-16T03:29:40.148599Z"
    },
    "papermill": {
     "duration": 64.726758,
     "end_time": "2022-06-16T03:29:40.152022",
     "exception": false,
     "start_time": "2022-06-16T03:28:35.425264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.73it/s]\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    num_workers=4\n",
    "    path=\"../input/debertabase/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-base\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "    \n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "predictions = []\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred7 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0ebfcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:29:40.296539Z",
     "iopub.status.busy": "2022-06-16T03:29:40.295814Z",
     "iopub.status.idle": "2022-06-16T03:32:27.477446Z",
     "shell.execute_reply": "2022-06-16T03:32:27.476172Z"
    },
    "papermill": {
     "duration": 167.253256,
     "end_time": "2022-06-16T03:32:27.479743",
     "exception": false,
     "start_time": "2022-06-16T03:29:40.226487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    num_workers=4\n",
    "    path=\"../input/debertalarge5fold/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    \n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "predictions = []\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred8 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b3193c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:32:27.634466Z",
     "iopub.status.busy": "2022-06-16T03:32:27.633865Z",
     "iopub.status.idle": "2022-06-16T03:33:43.747072Z",
     "shell.execute_reply": "2022-06-16T03:33:43.746156Z"
    },
    "papermill": {
     "duration": 76.189666,
     "end_time": "2022-06-16T03:33:43.748903",
     "exception": false,
     "start_time": "2022-06-16T03:32:27.559237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.74it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.76it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    num_workers=0\n",
    "    path=\"../input/electra/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"google/electra-large-discriminator\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 2, 4]\n",
    "\n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "predictions = []\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred10 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24af53ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:33:43.910654Z",
     "iopub.status.busy": "2022-06-16T03:33:43.910050Z",
     "iopub.status.idle": "2022-06-16T03:33:43.926272Z",
     "shell.execute_reply": "2022-06-16T03:33:43.925502Z"
    },
    "papermill": {
     "duration": 0.097607,
     "end_time": "2022-06-16T03:33:43.928045",
     "exception": false,
     "start_time": "2022-06-16T03:33:43.830438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n",
    "        self._init_weights(self.attention)\n",
    "        self.linear = nn.Linear(self.config.hidden_size, 1)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs[0]\n",
    "        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        out = sum_embeddings / sum_mask\n",
    "        \n",
    "        out = self.layer_norm1(out)\n",
    "        output = self.fc(out)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff6f8f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:33:44.086392Z",
     "iopub.status.busy": "2022-06-16T03:33:44.085583Z",
     "iopub.status.idle": "2022-06-16T03:36:34.819138Z",
     "shell.execute_reply": "2022-06-16T03:36:34.818227Z"
    },
    "papermill": {
     "duration": 170.814389,
     "end_time": "2022-06-16T03:36:34.821164",
     "exception": false,
     "start_time": "2022-06-16T03:33:44.006775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.75it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.80it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    num_workers=4\n",
    "    path=\"../input/debertalargelayernorm/\"\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=133\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    \n",
    "CFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "predictions = []\n",
    "for fold in CFG.trn_fold:\n",
    "    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=device)\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "pred9 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19394adf",
   "metadata": {
    "papermill": {
     "duration": 0.081734,
     "end_time": "2022-06-16T03:36:34.990279",
     "exception": false,
     "start_time": "2022-06-16T03:36:34.908545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2.Roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "166e1499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:35.159012Z",
     "iopub.status.busy": "2022-06-16T03:36:35.158326Z",
     "iopub.status.idle": "2022-06-16T03:36:35.165535Z",
     "shell.execute_reply": "2022-06-16T03:36:35.164837Z"
    },
    "papermill": {
     "duration": 0.094174,
     "end_time": "2022-06-16T03:36:35.167328",
     "exception": false,
     "start_time": "2022-06-16T03:36:35.073154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(seed=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ab09410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:35.334147Z",
     "iopub.status.busy": "2022-06-16T03:36:35.333553Z",
     "iopub.status.idle": "2022-06-16T03:36:35.581511Z",
     "shell.execute_reply": "2022-06-16T03:36:35.580785Z"
    },
    "papermill": {
     "duration": 0.333749,
     "end_time": "2022-06-16T03:36:35.583689",
     "exception": false,
     "start_time": "2022-06-16T03:36:35.249940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class CFG:\n",
    "    num_workers: Optional[int] = 4\n",
    "    config_path: Optional[str] = '../input/robertalarge'\n",
    "    model_path: Optional[str] = '../input/phrase-matching-roberta-training-pytorch-wandb'\n",
    "    model_name: Optional[str] = 'roberta-large'\n",
    "    batch_size: Optional[int] = 32\n",
    "    max_len: Optional[int] = 128\n",
    "    seed: Optional[int] = 2019\n",
    "    num_targets: Optional[int] = 1\n",
    "    n_folds: Optional[int] = 5\n",
    "    tokenizer = AutoTokenizer.from_pretrained('../input/robertalarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133d5336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:35.751427Z",
     "iopub.status.busy": "2022-06-16T03:36:35.750779Z",
     "iopub.status.idle": "2022-06-16T03:36:35.768632Z",
     "shell.execute_reply": "2022-06-16T03:36:35.767949Z"
    },
    "papermill": {
     "duration": 0.103319,
     "end_time": "2022-06-16T03:36:35.770473",
     "exception": false,
     "start_time": "2022-06-16T03:36:35.667154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = '../input/us-patent-phrase-to-phrase-matching'\n",
    "test = pd.read_csv(os.path.join(PATH, 'test.csv'))\n",
    "sub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a46e4284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:35.940410Z",
     "iopub.status.busy": "2022-06-16T03:36:35.940151Z",
     "iopub.status.idle": "2022-06-16T03:36:35.949944Z",
     "shell.execute_reply": "2022-06-16T03:36:35.949136Z"
    },
    "papermill": {
     "duration": 0.097319,
     "end_time": "2022-06-16T03:36:35.952219",
     "exception": false,
     "start_time": "2022-06-16T03:36:35.854900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_mapping = {\n",
    "        \"A\": \"Human Necessities\",\n",
    "        \"B\": \"Operations and Transport\",\n",
    "        \"C\": \"Chemistry and Metallurgy\",\n",
    "        \"D\": \"Textiles\",\n",
    "        \"E\": \"Fixed Constructions\",\n",
    "        \"F\": \"Mechanical Engineering\",\n",
    "        \"G\": \"Physics\",\n",
    "        \"H\": \"Electricity\",\n",
    "        \"Y\": \"Emerging Cross-Sectional Technologies\",\n",
    "}\n",
    "    \n",
    "test.context = test.context.apply(lambda x: context_mapping[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5940e77b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:36.123210Z",
     "iopub.status.busy": "2022-06-16T03:36:36.122887Z",
     "iopub.status.idle": "2022-06-16T03:36:36.130394Z",
     "shell.execute_reply": "2022-06-16T03:36:36.129701Z"
    },
    "papermill": {
     "duration": 0.095259,
     "end_time": "2022-06-16T03:36:36.132018",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.036759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PhraseDataset:\n",
    "    def __init__(self, anchor, target, context, tokenizer, max_len):\n",
    "        self.anchor = anchor\n",
    "        self.target = target\n",
    "        self.context = context\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anchor = self.anchor[item]\n",
    "        context = self.context[item]\n",
    "        target = self.target[item]\n",
    "\n",
    "        encoded_text = CFG.tokenizer.encode_plus(\n",
    "            context + \" \" + anchor,\n",
    "            target,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        attention_mask = encoded_text[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fcbb981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:36.301168Z",
     "iopub.status.busy": "2022-06-16T03:36:36.300888Z",
     "iopub.status.idle": "2022-06-16T03:36:36.307632Z",
     "shell.execute_reply": "2022-06-16T03:36:36.306983Z"
    },
    "papermill": {
     "duration": 0.093183,
     "end_time": "2022-06-16T03:36:36.309397",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.216214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_fn(model, test_loader):  \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for data in tk0:\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(ids, mask)\n",
    "        predictions.append(output.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    return np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d74f05c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:36.478697Z",
     "iopub.status.busy": "2022-06-16T03:36:36.477966Z",
     "iopub.status.idle": "2022-06-16T03:36:36.488213Z",
     "shell.execute_reply": "2022-06-16T03:36:36.487479Z"
    },
    "papermill": {
     "duration": 0.095978,
     "end_time": "2022-06-16T03:36:36.489871",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.393893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatentModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatentModel, self).__init__()\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "\n",
    "        config = AutoConfig.from_pretrained(CFG.config_path)\n",
    "\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.transformer = AutoModel.from_pretrained(CFG.config_path, config=config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(config.hidden_size, CFG.num_targets)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(input_ids=ids, attention_mask=mask)\n",
    "        last_hidden_states = transformer_out[0]\n",
    "        last_hidden_states = self.dropout(torch.mean(last_hidden_states, 1))\n",
    "        logits1 = self.output(self.dropout1(last_hidden_states))\n",
    "        logits2 = self.output(self.dropout2(last_hidden_states))\n",
    "        logits3 = self.output(self.dropout3(last_hidden_states))\n",
    "        logits4 = self.output(self.dropout4(last_hidden_states))\n",
    "        logits5 = self.output(self.dropout5(last_hidden_states))\n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06d73f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:36.665312Z",
     "iopub.status.busy": "2022-06-16T03:36:36.664603Z",
     "iopub.status.idle": "2022-06-16T03:36:36.672004Z",
     "shell.execute_reply": "2022-06-16T03:36:36.671295Z"
    },
    "papermill": {
     "duration": 0.094878,
     "end_time": "2022-06-16T03:36:36.673673",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.578795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold(test, fold, seed=42):    \n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    test_dataset = PhraseDataset(\n",
    "        test.anchor.values,\n",
    "        test.target.values,\n",
    "        test.context.values,\n",
    "        CFG.tokenizer, \n",
    "        CFG.max_len\n",
    "    ) \n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                              batch_size=CFG.batch_size * 2, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    model = PatentModel()\n",
    "    \n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{CFG.model_path}/{CFG.model_name.replace(\"-\",\"_\")}_patent_model_{fold}.pth',\n",
    "        map_location=device\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    preds = inference_fn(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e4190f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:36.844928Z",
     "iopub.status.busy": "2022-06-16T03:36:36.844678Z",
     "iopub.status.idle": "2022-06-16T03:36:36.849602Z",
     "shell.execute_reply": "2022-06-16T03:36:36.848623Z"
    },
    "papermill": {
     "duration": 0.093845,
     "end_time": "2022-06-16T03:36:36.852047",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.758202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_model(test, seed):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for f in range(CFG.n_folds):    \n",
    "        preds = run_fold(test, f, seed) \n",
    "        predictions.append(preds)\n",
    "        \n",
    "    test_preds = np.column_stack(predictions)\n",
    "        \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e369f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:36:37.020822Z",
     "iopub.status.busy": "2022-06-16T03:36:37.020122Z",
     "iopub.status.idle": "2022-06-16T03:38:35.502003Z",
     "shell.execute_reply": "2022-06-16T03:38:35.501170Z"
    },
    "papermill": {
     "duration": 118.569069,
     "end_time": "2022-06-16T03:38:35.504013",
     "exception": false,
     "start_time": "2022-06-16T03:36:36.934944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pred2 =  np.mean(inference_model(test, CFG.seed),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf2d27",
   "metadata": {
    "papermill": {
     "duration": 0.091797,
     "end_time": "2022-06-16T03:38:35.696225",
     "exception": false,
     "start_time": "2022-06-16T03:38:35.604428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Bert for patent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c209aa1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:35.884524Z",
     "iopub.status.busy": "2022-06-16T03:38:35.883797Z",
     "iopub.status.idle": "2022-06-16T03:38:36.012212Z",
     "shell.execute_reply": "2022-06-16T03:38:36.011472Z"
    },
    "papermill": {
     "duration": 0.226533,
     "end_time": "2022-06-16T03:38:36.014324",
     "exception": false,
     "start_time": "2022-06-16T03:38:35.787791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31bff920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:36.202837Z",
     "iopub.status.busy": "2022-06-16T03:38:36.202582Z",
     "iopub.status.idle": "2022-06-16T03:38:36.206972Z",
     "shell.execute_reply": "2022-06-16T03:38:36.206164Z"
    },
    "papermill": {
     "duration": 0.117494,
     "end_time": "2022-06-16T03:38:36.226283",
     "exception": false,
     "start_time": "2022-06-16T03:38:36.108789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "    model_path = '../input/bertforpatentsbaseline5folds/'\n",
    "    \n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    num_fold = 5\n",
    "    epochs = 5\n",
    "    batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af6564d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:36.415497Z",
     "iopub.status.busy": "2022-06-16T03:38:36.414775Z",
     "iopub.status.idle": "2022-06-16T03:38:37.264238Z",
     "shell.execute_reply": "2022-06-16T03:38:37.263446Z"
    },
    "papermill": {
     "duration": 0.945408,
     "end_time": "2022-06-16T03:38:37.266471",
     "exception": false,
     "start_time": "2022-06-16T03:38:36.321063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{CFG.input_path}test.csv\")\n",
    "titles = pd.read_csv('../input/titles/titles.csv')\n",
    "test_df = test_df.merge(test_df.merge(titles, left_on='context', right_on='code', sort=False))\n",
    "test_df['input'] = test_df['title']+' '+test_df['anchor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6c72d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:37.461557Z",
     "iopub.status.busy": "2022-06-16T03:38:37.461305Z",
     "iopub.status.idle": "2022-06-16T03:38:37.525539Z",
     "shell.execute_reply": "2022-06-16T03:38:37.524803Z"
    },
    "papermill": {
     "duration": 0.160302,
     "end_time": "2022-06-16T03:38:37.527692",
     "exception": false,
     "start_time": "2022-06-16T03:38:37.367390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path}uspppm_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce538f2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:37.718653Z",
     "iopub.status.busy": "2022-06-16T03:38:37.717845Z",
     "iopub.status.idle": "2022-06-16T03:38:37.724319Z",
     "shell.execute_reply": "2022-06-16T03:38:37.723650Z"
    },
    "papermill": {
     "duration": 0.10325,
     "end_time": "2022-06-16T03:38:37.725925",
     "exception": false,
     "start_time": "2022-06-16T03:38:37.622675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InferDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input'].values.astype(str)\n",
    "        self.targets = df['target'].values.astype(str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.inputs[item]\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        return {\n",
    "        **tokenizer( inputs, targets ),\n",
    "        'label': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ee72d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:38:37.916648Z",
     "iopub.status.busy": "2022-06-16T03:38:37.916354Z",
     "iopub.status.idle": "2022-06-16T03:40:29.477142Z",
     "shell.execute_reply": "2022-06-16T03:40:29.476282Z"
    },
    "papermill": {
     "duration": 111.659194,
     "end_time": "2022-06-16T03:40:29.479487",
     "exception": false,
     "start_time": "2022-06-16T03:38:37.820293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bertforpatentsbaseline5folds/uspppm_1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bertforpatentsbaseline5folds/uspppm_1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bertforpatentsbaseline5folds/uspppm_1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bertforpatentsbaseline5folds/uspppm_1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bertforpatentsbaseline5folds/uspppm_2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bertforpatentsbaseline5folds/uspppm_2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bertforpatentsbaseline5folds/uspppm_2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bertforpatentsbaseline5folds/uspppm_2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bertforpatentsbaseline5folds/uspppm_3/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bertforpatentsbaseline5folds/uspppm_3\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bertforpatentsbaseline5folds/uspppm_3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bertforpatentsbaseline5folds/uspppm_3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bertforpatentsbaseline5folds/uspppm_4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bertforpatentsbaseline5folds/uspppm_4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bertforpatentsbaseline5folds/uspppm_4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bertforpatentsbaseline5folds/uspppm_4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "MMscaler = MinMaxScaler()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for fold in range(CFG.num_fold):\n",
    "    te_dataset = InferDataset(test_df)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path}uspppm_{fold}', num_labels=1)\n",
    "    trainer = Trainer(\n",
    "            model,\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    outputs = trainer.predict(te_dataset)\n",
    "    prediction = outputs.predictions.reshape(-1)\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "pred3 = np.mean(predictions, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "546a37c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:40:29.725868Z",
     "iopub.status.busy": "2022-06-16T03:40:29.725048Z",
     "iopub.status.idle": "2022-06-16T03:40:29.731423Z",
     "shell.execute_reply": "2022-06-16T03:40:29.730752Z"
    },
    "papermill": {
     "duration": 0.122267,
     "end_time": "2022-06-16T03:40:29.733162",
     "exception": false,
     "start_time": "2022-06-16T03:40:29.610895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5d864b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:40:29.962616Z",
     "iopub.status.busy": "2022-06-16T03:40:29.962348Z",
     "iopub.status.idle": "2022-06-16T03:40:29.968550Z",
     "shell.execute_reply": "2022-06-16T03:40:29.967866Z"
    },
    "papermill": {
     "duration": 0.123385,
     "end_time": "2022-06-16T03:40:29.970509",
     "exception": false,
     "start_time": "2022-06-16T03:40:29.847124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG_roberta:\n",
    "    num_workers=4\n",
    "    path=\"../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/\"  ##change\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"roberta-large\"  ##change\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=175  ##change\n",
    "    seed=99\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]\n",
    "class CFG_bertforpatent:\n",
    "    num_workers=4\n",
    "    path=\"../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/\"  ##change\n",
    "    config_path=path+'config.pth'\n",
    "    model=\"anferico/bert-for-patents\"  ##change\n",
    "    batch_size=32\n",
    "    fc_dropout=0.2\n",
    "    target_size=1\n",
    "    max_len=115  ##change\n",
    "    seed=99\n",
    "    n_fold=4\n",
    "    trn_fold=[0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87cae6d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:40:30.201214Z",
     "iopub.status.busy": "2022-06-16T03:40:30.200924Z",
     "iopub.status.idle": "2022-06-16T03:40:30.236286Z",
     "shell.execute_reply": "2022-06-16T03:40:30.235545Z"
    },
    "papermill": {
     "duration": 0.153894,
     "end_time": "2022-06-16T03:40:30.238240",
     "exception": false,
     "start_time": "2022-06-16T03:40:30.084346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "from transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = sp.stats.pearsonr(y_true, y_pred)[0]\n",
    "    return score\n",
    "\n",
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=1., emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "        \n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer(text,\n",
    "                           add_special_tokens=True,\n",
    "                           max_length=cfg.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self._init_weights(self.attention)\n",
    "        self.fgm = FGM(self.model)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        # feature = torch.mean(last_hidden_states, 1)\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55be223d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:40:30.464428Z",
     "iopub.status.busy": "2022-06-16T03:40:30.464166Z",
     "iopub.status.idle": "2022-06-16T03:42:23.483973Z",
     "shell.execute_reply": "2022-06-16T03:42:23.478941Z"
    },
    "papermill": {
     "duration": 113.140239,
     "end_time": "2022-06-16T03:42:23.489547",
     "exception": false,
     "start_time": "2022-06-16T03:40:30.349308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/added_tokens.json. We won't load it.\n",
      "loading file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/vocab.json\n",
      "loading file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/merges.txt\n",
      "loading file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/tokenizer.json\n",
      "loading file None\n",
      "loading file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/special_tokens_map.json\n",
      "loading file ../input/roberta6/63d73aa4-e891-11ec-9976-0242ac110002/tokenizer/tokenizer_config.json\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=42)\n",
    "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "cpc_texts = torch.load(\"../input/cpc-texts/cpc_texts.pth\")\n",
    "test['context_text'] = test['context'].map(cpc_texts)\n",
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "CFG_roberta.tokenizer = AutoTokenizer.from_pretrained(CFG_roberta.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG_roberta, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_roberta.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_roberta.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_roberta.trn_fold:\n",
    "    model = CustomModel(CFG_roberta, config_path=CFG_roberta.config_path, pretrained=False)\n",
    "    state = torch.load(CFG_roberta.path+f\"{CFG_roberta.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "    del model, state, prediction; gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "pred4 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f423bb17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:42:23.887794Z",
     "iopub.status.busy": "2022-06-16T03:42:23.887351Z",
     "iopub.status.idle": "2022-06-16T03:44:06.857321Z",
     "shell.execute_reply": "2022-06-16T03:44:06.856305Z"
    },
    "papermill": {
     "duration": 103.168136,
     "end_time": "2022-06-16T03:44:06.859271",
     "exception": false,
     "start_time": "2022-06-16T03:42:23.691135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/tokenizer/added_tokens.json. We won't load it.\n",
      "loading file ../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/tokenizer/vocab.txt\n",
      "loading file ../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/tokenizer/tokenizer.json\n",
      "loading file None\n",
      "loading file ../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/tokenizer/special_tokens_map.json\n",
      "loading file ../input/bertforpatent2roberta1/bert_for_patent2/f17f0b1e-dc40-11ec-a8f8-0242ac110002/tokenizer/tokenizer_config.json\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=42)\n",
    "test = pd.read_csv(INPUT_DIR+'test.csv')\n",
    "submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n",
    "cpc_texts = torch.load(CFG_bertforpatent.path+\"cpc_texts.pth\")\n",
    "test['context_text'] = test['context'].map(cpc_texts)\n",
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n",
    "CFG_bertforpatent.tokenizer = AutoTokenizer.from_pretrained(CFG_bertforpatent.path+'tokenizer/')\n",
    "test_dataset = TestDataset(CFG_bertforpatent, test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=CFG_bertforpatent.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=CFG_bertforpatent.num_workers, pin_memory=True, drop_last=False)\n",
    "predictions = []\n",
    "for fold in CFG_bertforpatent.trn_fold:\n",
    "    model = CustomModel(CFG_bertforpatent, config_path=CFG_bertforpatent.config_path, pretrained=False)\n",
    "    state = torch.load(CFG_bertforpatent.path+f\"{CFG_bertforpatent.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                       map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    prediction = inference_fn(test_loader, model, device)\n",
    "    predictions.append(prediction)\n",
    "del model, state, prediction; gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "pred5 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9f2ce57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:44:07.119875Z",
     "iopub.status.busy": "2022-06-16T03:44:07.119617Z",
     "iopub.status.idle": "2022-06-16T03:46:07.379628Z",
     "shell.execute_reply": "2022-06-16T03:46:07.378308Z"
    },
    "papermill": {
     "duration": 120.389091,
     "end_time": "2022-06-16T03:46:07.381591",
     "exception": false,
     "start_time": "2022-06-16T03:44:06.992500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "      <td>G02</td>\n",
       "      <td>OPTICS</td>\n",
       "      <td>G</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHYSICS. OPTICS</td>\n",
       "      <td>opc drum[sep]inorganic photoconductor drum[sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "      <td>F23</td>\n",
       "      <td>COMBUSTION APPARATUS; COMBUSTION PROCESSES</td>\n",
       "      <td>F</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n",
       "      <td>adjust gas flow[sep]altering gas flow[sep]mech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "      <td>B60</td>\n",
       "      <td>VEHICLES IN GENERAL</td>\n",
       "      <td>B</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n",
       "      <td>lower trunnion[sep]lower locating[sep]performi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "      <td>D06</td>\n",
       "      <td>TREATMENT OF TEXTILES OR THE LIKE; LAUNDERING;...</td>\n",
       "      <td>D</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n",
       "      <td>cap component[sep]upper portion[sep]textiles; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "      <td>H04</td>\n",
       "      <td>ELECTRIC COMMUNICATION TECHNIQUE</td>\n",
       "      <td>H</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n",
       "      <td>neural stimulation[sep]artificial neural netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target  \\\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
       "2  36baf228038e314b      lower trunnion                 lower locating   \n",
       "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
       "\n",
       "  context code                                              title section  \\\n",
       "0     G02  G02                                             OPTICS       G   \n",
       "1     F23  F23         COMBUSTION APPARATUS; COMBUSTION PROCESSES       F   \n",
       "2     B60  B60                                VEHICLES IN GENERAL       B   \n",
       "3     D06  D06  TREATMENT OF TEXTILES OR THE LIKE; LAUNDERING;...       D   \n",
       "4     H04  H04                   ELECTRIC COMMUNICATION TECHNIQUE       H   \n",
       "\n",
       "   class subclass  group  main_group  \\\n",
       "0    2.0      NaN    NaN         NaN   \n",
       "1   23.0      NaN    NaN         NaN   \n",
       "2   60.0      NaN    NaN         NaN   \n",
       "3    6.0      NaN    NaN         NaN   \n",
       "4    4.0      NaN    NaN         NaN   \n",
       "\n",
       "                                        context_text  \\\n",
       "0                                    PHYSICS. OPTICS   \n",
       "1  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...   \n",
       "2  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...   \n",
       "3  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...   \n",
       "4      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE   \n",
       "\n",
       "                                                text  \n",
       "0  opc drum[sep]inorganic photoconductor drum[sep...  \n",
       "1  adjust gas flow[sep]altering gas flow[sep]mech...  \n",
       "2  lower trunnion[sep]lower locating[sep]performi...  \n",
       "3  cap component[sep]upper portion[sep]textiles; ...  \n",
       "4  neural stimulation[sep]artificial neural netwo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Didn't find file ../input/deberta-v3-large/deberta-v3-large/added_tokens.json. We won't load it.\n",
      "Didn't find file ../input/deberta-v3-large/deberta-v3-large/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ../input/deberta-v3-large/deberta-v3-large/tokenizer.json. We won't load it.\n",
      "loading file ../input/deberta-v3-large/deberta-v3-large/spm.model\n",
      "loading file None\n",
      "loading file None\n",
      "loading file ../input/deberta-v3-large/deberta-v3-large/tokenizer_config.json\n",
      "loading file None\n",
      "loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      " 25%|██▌       | 1/4 [00:28<01:26, 28.70s/it]loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      " 50%|█████     | 2/4 [00:58<00:59, 29.57s/it]loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      " 75%|███████▌  | 3/4 [01:29<00:30, 30.02s/it]loading configuration file ../input/deberta-v3-large/deberta-v3-large/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-large/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "100%|██████████| 4/4 [01:58<00:00, 29.66s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "class CFG_DEB_SIMPLE:\n",
    "    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "    model_path = '../input/deberta-v3-large/deberta-v3-large'\n",
    "    \n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    num_fold = 4\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    max_input_length = 130\n",
    "    batch_size = 64\n",
    "    num_workers = 2\n",
    "\n",
    "test_df = pd.read_csv(f\"{CFG_DEB_SIMPLE.input_path}test.csv\")\n",
    "titles = pd.read_csv('../input/cpc-codes/titles.csv')\n",
    "# test_df = test_df.merge(titles, left_on='context', right_on='code')\n",
    "test_df = test_df.merge(test_df.merge(titles, left_on='context', right_on='code', sort=False))\n",
    "# ====================================================\n",
    "# CPC Data\n",
    "# ====================================================\n",
    "cpc_texts = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")\n",
    "test_df['context_text'] = test_df['context'].map(cpc_texts)\n",
    "test_df['text'] = test_df['anchor'] + '[SEP]' + test_df['target'] + '[SEP]'  + test_df['context_text']\n",
    "test_df['text'] = test_df['text'].apply(str.lower)\n",
    "display(test_df.head())\n",
    "\n",
    "tokenizer_deberta_v3 = AutoTokenizer.from_pretrained(CFG_DEB_SIMPLE.model_path)\n",
    "\n",
    "class Custom_Bert_Simple(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(model_path)\n",
    "        config.num_labels = 1\n",
    "        self.base = AutoModelForSequenceClassification.from_config(config=config)\n",
    "        dim = config.hidden_size\n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "        self.cls = nn.Linear(dim,1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "        base_output = self.base(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids )\n",
    "\n",
    "        output = base_output[0]\n",
    "        if labels is None:\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            return (nn.MSELoss()(torch.squeeze(output,1),labels), output)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_length):\n",
    "        self.text = df['text'].values.astype(str)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.text[item]\n",
    "        \n",
    "        inputs = self.tokenizer(inputs,\n",
    "                    max_length=self.max_input_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True )\n",
    "        return torch.as_tensor(inputs['input_ids'], dtype=torch.long),\\\n",
    "               torch.as_tensor(inputs['token_type_ids'], dtype=torch.long),\\\n",
    "               torch.as_tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "\n",
    "def valid_fn(valid_loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for step, batch in enumerate(valid_loader):\n",
    "        input_ids, token_type_ids, attention_mask = [i.to(device) for i in batch]\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(input_ids, attention_mask, token_type_ids)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "predictions = []\n",
    "MMscaler = MinMaxScaler()\n",
    "te_dataset = TestDataset(test_df, tokenizer_deberta_v3, CFG_DEB_SIMPLE.max_input_length)\n",
    "te_dataloader = DataLoader(te_dataset,\n",
    "                              batch_size=CFG_DEB_SIMPLE.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG_DEB_SIMPLE.num_workers, pin_memory=True, drop_last=False)\n",
    "for fold in tqdm(range(CFG_DEB_SIMPLE.num_fold)):\n",
    "    \n",
    "    model = Custom_Bert_Simple(CFG_DEB_SIMPLE.model_path)\n",
    "    model.load_state_dict(torch.load('../input/us-patent-deberta-simple/microsoft_deberta-v3-large_best{}.pth'.format(fold))['model'])\n",
    "    model.to('cuda')\n",
    "    \n",
    "    outputs = valid_fn(te_dataloader, model, 'cuda')\n",
    "    prediction = outputs.reshape(-1)\n",
    "    predictions.append(MMscaler.fit_transform(prediction.reshape(-1,1)).reshape(-1))\n",
    "\n",
    "pred11 = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f173766",
   "metadata": {
    "papermill": {
     "duration": 0.134628,
     "end_time": "2022-06-16T03:46:07.672271",
     "exception": false,
     "start_time": "2022-06-16T03:46:07.537643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31e85163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:07.944857Z",
     "iopub.status.busy": "2022-06-16T03:46:07.944577Z",
     "iopub.status.idle": "2022-06-16T03:46:07.961691Z",
     "shell.execute_reply": "2022-06-16T03:46:07.960994Z"
    },
    "papermill": {
     "duration": 0.156788,
     "end_time": "2022-06-16T03:46:07.963955",
     "exception": false,
     "start_time": "2022-06-16T03:46:07.807167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024, 0.024, 0.064, 0.16, 0.16, 0.064, 0.024, 0.08, 0.08, 0.16, 0.16]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 0.03# 0.8358  Deberta (public code)\n",
    "w2 = 0.03# 0.8143  Roberta (public code)\n",
    "w3 = 0.08# 0.826   BERT for patent (public code version 2)\n",
    "w4 = 0.2# 0.8209  Roberta (jingyu)\n",
    "w5 = 0.2# 0.8294  BERT for patent (jingyu)\n",
    "w6 = 0.08# 0.8331  Deberta (gongzheng)   CV 0.860\n",
    "w7 = 0.03# 0.8226  Deberta-base (gongzheng)  CV 0.852\n",
    "w8 = 0.1# 0.8367   Deberta-5-fold (gongzheng)  CV 0.8625\n",
    "w9 = 0.1# 0.8383   Deberta-layer-norm-5-fold (gongzheng) CV 0.8622\n",
    "w10 = 0.2# 0.834    electra (gongzheng)\n",
    "w11 = 0.2#  0.8392  Deberta  https://www.kaggle.com/code/surilee/inference-bert-for-uspatents-deepshare\n",
    "\n",
    "w_list = [w1, w2, w3, w4, w5, w6, w7, w8, w9, w10, w11]\n",
    "w_list = [w / sum(w_list) for w in w_list]\n",
    "w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cb3dad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:08.238450Z",
     "iopub.status.busy": "2022-06-16T03:46:08.237603Z",
     "iopub.status.idle": "2022-06-16T03:46:08.252651Z",
     "shell.execute_reply": "2022-06-16T03:46:08.251981Z"
    },
    "papermill": {
     "duration": 0.152719,
     "end_time": "2022-06-16T03:46:08.254616",
     "exception": false,
     "start_time": "2022-06-16T03:46:08.101897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "MMscaler = MinMaxScaler()\n",
    "\n",
    "pred1_mm = MMscaler.fit_transform(pred1.reshape(-1,1)).reshape(-1)\n",
    "pred2_mm = MMscaler.fit_transform(pred2.reshape(-1,1)).reshape(-1)\n",
    "pred3_mm = MMscaler.fit_transform(pred3.reshape(-1,1)).reshape(-1)\n",
    "pred4_mm = MMscaler.fit_transform(pred4.reshape(-1,1)).reshape(-1)\n",
    "pred5_mm = MMscaler.fit_transform(pred5.reshape(-1,1)).reshape(-1)\n",
    "pred6_mm = MMscaler.fit_transform(pred6.reshape(-1,1)).reshape(-1)\n",
    "pred7_mm = MMscaler.fit_transform(pred7.reshape(-1,1)).reshape(-1)\n",
    "pred8_mm = MMscaler.fit_transform(pred8.reshape(-1,1)).reshape(-1)\n",
    "pred9_mm = MMscaler.fit_transform(pred9.reshape(-1,1)).reshape(-1)\n",
    "pred10_mm = MMscaler.fit_transform(pred10.reshape(-1,1)).reshape(-1)\n",
    "pred11_mm = MMscaler.fit_transform(pred11.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "final_predictions =  pred1_mm * w_list[0] + pred2_mm * w_list[1] + pred3_mm * w_list[2] + pred4_mm * w_list[3] + pred5_mm * w_list[4] + pred6_mm * w_list[5] + pred7_mm * w_list[6] + pred8_mm * w_list[7] + pred9_mm * w_list[8] + pred10_mm * w_list[9] + pred11_mm * w_list[10]\n",
    "# final_predictions = pred11_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23da0e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:08.542659Z",
     "iopub.status.busy": "2022-06-16T03:46:08.542400Z",
     "iopub.status.idle": "2022-06-16T03:46:08.546528Z",
     "shell.execute_reply": "2022-06-16T03:46:08.545686Z"
    },
    "papermill": {
     "duration": 0.141983,
     "end_time": "2022-06-16T03:46:08.548647",
     "exception": false,
     "start_time": "2022-06-16T03:46:08.406664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_samples = list(zip(pred1_mm, pred2_mm, pred3_mm, pred4_mm, pred5_mm, pred6_mm, pred7_mm, pred8_mm, pred9_mm, pred10_mm, pred11_mm))\n",
    "\n",
    "# final_predictions = []\n",
    "\n",
    "# for pred_sample in pred_samples:\n",
    "#     max_pred, min_pred = max(pred_sample), min(pred_sample)\n",
    "#     max_pred_id, min_pred_id = pred_sample.index(max_pred), pred_sample.index(min_pred)\n",
    "    \n",
    "#     pred_w_list = w_list.copy()\n",
    "#     pred_w_list[max_pred_id] = 0\n",
    "#     pred_w_list[min_pred_id] = 0\n",
    "    \n",
    "#     prediction = 0\n",
    "#     for each_model_predict, each_w in zip(pred_sample, pred_w_list):\n",
    "#         prediction += each_model_predict * each_w\n",
    "    \n",
    "#     prediction = prediction / sum(pred_w_list)\n",
    "    \n",
    "# #     prediction = (sum(pred_sample) - max(pred_sample) - min(pred_sample)) / (len(pred_sample) - 2)\n",
    "#     final_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2457807d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:08.818539Z",
     "iopub.status.busy": "2022-06-16T03:46:08.818274Z",
     "iopub.status.idle": "2022-06-16T03:46:08.821834Z",
     "shell.execute_reply": "2022-06-16T03:46:08.821147Z"
    },
    "papermill": {
     "duration": 0.142,
     "end_time": "2022-06-16T03:46:08.823612",
     "exception": false,
     "start_time": "2022-06-16T03:46:08.681612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_samples = list(zip(pred1_mm, pred2_mm, pred3_mm, pred4_mm, pred5_mm, pred6_mm, pred7_mm, pred8_mm, pred9_mm, pred10_mm, pred11_mm))\n",
    "\n",
    "# final_predictions = []\n",
    "\n",
    "# for pred_sample in pred_samples:\n",
    "#     prediction = (sum(pred_sample) - max(pred_sample) - min(pred_sample)) / (len(pred_sample) - 2)\n",
    "#     final_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9433660a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:09.096144Z",
     "iopub.status.busy": "2022-06-16T03:46:09.095839Z",
     "iopub.status.idle": "2022-06-16T03:46:09.125162Z",
     "shell.execute_reply": "2022-06-16T03:46:09.124407Z"
    },
    "papermill": {
     "duration": 0.167553,
     "end_time": "2022-06-16T03:46:09.127040",
     "exception": false,
     "start_time": "2022-06-16T03:46:08.959487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _upd_score_between(data, thresholds, value):\n",
    "    \"\"\"\\o/\"\"\"\n",
    "    mask_th = data.between(*thresholds, inclusive='both')\n",
    "    data[mask_th] = value\n",
    "\n",
    "\n",
    "def upd_score(data, th_dict=None):\n",
    "    \"\"\"\\o/\"\"\"\n",
    "    if isinstance(data, pd.Series):\n",
    "        result = data.copy()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "    if not th_dict:        \n",
    "        th_dict = {\n",
    "            '0': 0.02,\n",
    "            '.25': (0.24, 0.26),\n",
    "            '.50': (0.49, 0.51),\n",
    "            '.75': (0.74, 0.76),\n",
    "            '1': 0.98\n",
    "        }\n",
    "\n",
    "    if isinstance(th_dict, dict):    \n",
    "        th0 = th_dict.get('0')\n",
    "        th25 = th_dict.get('.25')\n",
    "        th50 = th_dict.get('.50')\n",
    "        th75 = th_dict.get('.75')\n",
    "        th100 = th_dict.get('1')\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "    if th0:\n",
    "        if isinstance(th0, float):\n",
    "            th0 = (result.min(), th0)\n",
    "        \n",
    "        if isinstance(th0, tuple):\n",
    "            _upd_score_between(result, th0, 0)\n",
    "    \n",
    "    if th25 and isinstance(th25, tuple):\n",
    "        _upd_score_between(result, th25, 0.25)\n",
    "\n",
    "    if th50 and isinstance(th50, tuple):\n",
    "        _upd_score_between(result, th50, 0.50)\n",
    "            \n",
    "    if th75 and isinstance(th75, tuple):\n",
    "        _upd_score_between(result, th75, 0.75)\n",
    "            \n",
    "    if th100:\n",
    "        if isinstance(th100, float):\n",
    "            th100 = (th100, result.max())\n",
    "        \n",
    "        if isinstance(th100, tuple):\n",
    "            _upd_score_between(result, th100, 1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "thresholds_dict = {\n",
    "    '0': 0.02,\n",
    "    '.25': (0.24, 0.26),\n",
    "    '.50': (0.49, 0.51),\n",
    "    '.75': (0.74, 0.76),\n",
    "    '1': 0.98\n",
    "}\n",
    "\n",
    "\n",
    "sub['score'] = final_predictions\n",
    "sub['score'] = upd_score(sub['score'], thresholds_dict)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d21e9",
   "metadata": {
    "papermill": {
     "duration": 0.136062,
     "end_time": "2022-06-16T03:46:09.396885",
     "exception": false,
     "start_time": "2022-06-16T03:46:09.260823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a710ad7",
   "metadata": {
    "papermill": {
     "duration": 0.133876,
     "end_time": "2022-06-16T03:46:09.666525",
     "exception": false,
     "start_time": "2022-06-16T03:46:09.532649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48692cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:09.941586Z",
     "iopub.status.busy": "2022-06-16T03:46:09.941318Z",
     "iopub.status.idle": "2022-06-16T03:46:09.951777Z",
     "shell.execute_reply": "2022-06-16T03:46:09.950939Z"
    },
    "papermill": {
     "duration": 0.151343,
     "end_time": "2022-06-16T03:46:09.953548",
     "exception": false,
     "start_time": "2022-06-16T03:46:09.802205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0.513264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0.692246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0.468795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>0.266728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     score\n",
       "0  4112d61851461f60  0.513264\n",
       "1  09e418c93a776564  0.692246\n",
       "2  36baf228038e314b  0.468795\n",
       "3  1f37ead645e7f0c8  0.266728\n",
       "4  71a5b6ad068d531f  0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7263469c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:10.230872Z",
     "iopub.status.busy": "2022-06-16T03:46:10.230611Z",
     "iopub.status.idle": "2022-06-16T03:46:10.242467Z",
     "shell.execute_reply": "2022-06-16T03:46:10.241763Z"
    },
    "papermill": {
     "duration": 0.151378,
     "end_time": "2022-06-16T03:46:10.244254",
     "exception": false,
     "start_time": "2022-06-16T03:46:10.092876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub['pred1'] = pred1_mm\n",
    "sub['pred2'] = pred2_mm\n",
    "sub['pred3'] = pred3_mm\n",
    "sub['pred4'] = pred4_mm\n",
    "sub['pred5'] = pred5_mm\n",
    "sub['pred6'] = pred6_mm\n",
    "sub['pred7'] = pred7_mm\n",
    "sub['pred8'] = pred8_mm\n",
    "sub['pred9'] = pred9_mm\n",
    "sub['pred10'] = pred10_mm\n",
    "sub['pred11'] = pred11_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3df1138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T03:46:10.517797Z",
     "iopub.status.busy": "2022-06-16T03:46:10.517236Z",
     "iopub.status.idle": "2022-06-16T03:46:10.540744Z",
     "shell.execute_reply": "2022-06-16T03:46:10.539988Z"
    },
    "papermill": {
     "duration": 0.16237,
     "end_time": "2022-06-16T03:46:10.542531",
     "exception": false,
     "start_time": "2022-06-16T03:46:10.380161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>pred11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0.513264</td>\n",
       "      <td>0.548070</td>\n",
       "      <td>0.582516</td>\n",
       "      <td>0.470140</td>\n",
       "      <td>0.523272</td>\n",
       "      <td>0.542626</td>\n",
       "      <td>0.412257</td>\n",
       "      <td>0.599047</td>\n",
       "      <td>0.574789</td>\n",
       "      <td>0.556047</td>\n",
       "      <td>0.638238</td>\n",
       "      <td>0.325940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0.692246</td>\n",
       "      <td>0.722803</td>\n",
       "      <td>0.741248</td>\n",
       "      <td>0.650935</td>\n",
       "      <td>0.733734</td>\n",
       "      <td>0.624701</td>\n",
       "      <td>0.707529</td>\n",
       "      <td>0.712458</td>\n",
       "      <td>0.750050</td>\n",
       "      <td>0.728954</td>\n",
       "      <td>0.758063</td>\n",
       "      <td>0.600674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0.468795</td>\n",
       "      <td>0.435978</td>\n",
       "      <td>0.407745</td>\n",
       "      <td>0.433883</td>\n",
       "      <td>0.479464</td>\n",
       "      <td>0.429251</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>0.511296</td>\n",
       "      <td>0.526621</td>\n",
       "      <td>0.501007</td>\n",
       "      <td>0.426838</td>\n",
       "      <td>0.514221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>0.266728</td>\n",
       "      <td>0.290185</td>\n",
       "      <td>0.287422</td>\n",
       "      <td>0.254011</td>\n",
       "      <td>0.258861</td>\n",
       "      <td>0.242358</td>\n",
       "      <td>0.253762</td>\n",
       "      <td>0.244287</td>\n",
       "      <td>0.234795</td>\n",
       "      <td>0.235337</td>\n",
       "      <td>0.316446</td>\n",
       "      <td>0.287925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.112711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474c874d0c07bd21</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.467670</td>\n",
       "      <td>0.495716</td>\n",
       "      <td>0.471766</td>\n",
       "      <td>0.488659</td>\n",
       "      <td>0.498857</td>\n",
       "      <td>0.466096</td>\n",
       "      <td>0.512878</td>\n",
       "      <td>0.480865</td>\n",
       "      <td>0.478713</td>\n",
       "      <td>0.579902</td>\n",
       "      <td>0.499533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>442c114ed5c4e3c9</td>\n",
       "      <td>0.418388</td>\n",
       "      <td>0.468271</td>\n",
       "      <td>0.486066</td>\n",
       "      <td>0.367578</td>\n",
       "      <td>0.508660</td>\n",
       "      <td>0.340060</td>\n",
       "      <td>0.475942</td>\n",
       "      <td>0.475008</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>0.447965</td>\n",
       "      <td>0.297359</td>\n",
       "      <td>0.459802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b8ae62ea5e1d8bdb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>faaddaf8fcba8a3f</td>\n",
       "      <td>0.288120</td>\n",
       "      <td>0.300080</td>\n",
       "      <td>0.294383</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.283252</td>\n",
       "      <td>0.238643</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.326393</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.320707</td>\n",
       "      <td>0.362896</td>\n",
       "      <td>0.253126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ae0262c02566d2ce</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a8808e31641e856d</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.268362</td>\n",
       "      <td>0.231681</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>0.227576</td>\n",
       "      <td>0.249689</td>\n",
       "      <td>0.263676</td>\n",
       "      <td>0.258595</td>\n",
       "      <td>0.202395</td>\n",
       "      <td>0.215285</td>\n",
       "      <td>0.203273</td>\n",
       "      <td>0.251305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16ae4b99d3601e60</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.294652</td>\n",
       "      <td>0.283118</td>\n",
       "      <td>0.253597</td>\n",
       "      <td>0.250524</td>\n",
       "      <td>0.251363</td>\n",
       "      <td>0.264081</td>\n",
       "      <td>0.248899</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.268462</td>\n",
       "      <td>0.229380</td>\n",
       "      <td>0.273060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25c555ca3d5a2092</td>\n",
       "      <td>0.764862</td>\n",
       "      <td>0.727655</td>\n",
       "      <td>0.675018</td>\n",
       "      <td>0.754568</td>\n",
       "      <td>0.735165</td>\n",
       "      <td>0.762709</td>\n",
       "      <td>0.728253</td>\n",
       "      <td>0.803228</td>\n",
       "      <td>0.794012</td>\n",
       "      <td>0.798070</td>\n",
       "      <td>0.787512</td>\n",
       "      <td>0.774945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5203a36c501f1b7c</td>\n",
       "      <td>0.829651</td>\n",
       "      <td>0.869160</td>\n",
       "      <td>0.729004</td>\n",
       "      <td>0.808094</td>\n",
       "      <td>0.791773</td>\n",
       "      <td>0.791389</td>\n",
       "      <td>0.856201</td>\n",
       "      <td>0.851188</td>\n",
       "      <td>0.877980</td>\n",
       "      <td>0.826610</td>\n",
       "      <td>0.841518</td>\n",
       "      <td>0.875223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b9fdc772bb8fd61c</td>\n",
       "      <td>0.762887</td>\n",
       "      <td>0.745736</td>\n",
       "      <td>0.757120</td>\n",
       "      <td>0.735038</td>\n",
       "      <td>0.769245</td>\n",
       "      <td>0.754177</td>\n",
       "      <td>0.733222</td>\n",
       "      <td>0.806421</td>\n",
       "      <td>0.791540</td>\n",
       "      <td>0.773154</td>\n",
       "      <td>0.769165</td>\n",
       "      <td>0.759415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7aa5908a77a7ec24</td>\n",
       "      <td>0.334165</td>\n",
       "      <td>0.329810</td>\n",
       "      <td>0.471189</td>\n",
       "      <td>0.296783</td>\n",
       "      <td>0.413124</td>\n",
       "      <td>0.290691</td>\n",
       "      <td>0.324725</td>\n",
       "      <td>0.334515</td>\n",
       "      <td>0.314764</td>\n",
       "      <td>0.311384</td>\n",
       "      <td>0.363792</td>\n",
       "      <td>0.288924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>d19ef3979396d47e</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.334824</td>\n",
       "      <td>0.233763</td>\n",
       "      <td>0.236623</td>\n",
       "      <td>0.217371</td>\n",
       "      <td>0.264921</td>\n",
       "      <td>0.210674</td>\n",
       "      <td>0.261868</td>\n",
       "      <td>0.243389</td>\n",
       "      <td>0.252132</td>\n",
       "      <td>0.237239</td>\n",
       "      <td>0.260456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fd83613b7843f5e1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.032187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2a619016908bfa45</td>\n",
       "      <td>0.511499</td>\n",
       "      <td>0.488599</td>\n",
       "      <td>0.562773</td>\n",
       "      <td>0.454368</td>\n",
       "      <td>0.578941</td>\n",
       "      <td>0.438615</td>\n",
       "      <td>0.485668</td>\n",
       "      <td>0.525461</td>\n",
       "      <td>0.530133</td>\n",
       "      <td>0.516070</td>\n",
       "      <td>0.530340</td>\n",
       "      <td>0.513335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>733979d75f59770d</td>\n",
       "      <td>0.345127</td>\n",
       "      <td>0.344127</td>\n",
       "      <td>0.336324</td>\n",
       "      <td>0.354399</td>\n",
       "      <td>0.396093</td>\n",
       "      <td>0.349780</td>\n",
       "      <td>0.338782</td>\n",
       "      <td>0.299137</td>\n",
       "      <td>0.283303</td>\n",
       "      <td>0.279560</td>\n",
       "      <td>0.306789</td>\n",
       "      <td>0.398741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     score     pred1     pred2     pred3     pred4  \\\n",
       "0   4112d61851461f60  0.513264  0.548070  0.582516  0.470140  0.523272   \n",
       "1   09e418c93a776564  0.692246  0.722803  0.741248  0.650935  0.733734   \n",
       "2   36baf228038e314b  0.468795  0.435978  0.407745  0.433883  0.479464   \n",
       "3   1f37ead645e7f0c8  0.266728  0.290185  0.287422  0.254011  0.258861   \n",
       "4   71a5b6ad068d531f  0.000000  0.013673  0.026354  0.000000  0.000095   \n",
       "5   474c874d0c07bd21  0.500000  0.467670  0.495716  0.471766  0.488659   \n",
       "6   442c114ed5c4e3c9  0.418388  0.468271  0.486066  0.367578  0.508660   \n",
       "7   b8ae62ea5e1d8bdb  0.000000  0.000000  0.000130  0.002789  0.000023   \n",
       "8   faaddaf8fcba8a3f  0.288120  0.300080  0.294383  0.238507  0.283252   \n",
       "9   ae0262c02566d2ce  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "10  a8808e31641e856d  0.231606  0.268362  0.231681  0.218973  0.227576   \n",
       "11  16ae4b99d3601e60  0.250000  0.294652  0.283118  0.253597  0.250524   \n",
       "12  25c555ca3d5a2092  0.764862  0.727655  0.675018  0.754568  0.735165   \n",
       "13  5203a36c501f1b7c  0.829651  0.869160  0.729004  0.808094  0.791773   \n",
       "14  b9fdc772bb8fd61c  0.762887  0.745736  0.757120  0.735038  0.769245   \n",
       "15  7aa5908a77a7ec24  0.334165  0.329810  0.471189  0.296783  0.413124   \n",
       "16  d19ef3979396d47e  0.250000  0.334824  0.233763  0.236623  0.217371   \n",
       "17  fd83613b7843f5e1  0.000000  0.000553  0.007345  0.032187  0.000000   \n",
       "18  2a619016908bfa45  0.511499  0.488599  0.562773  0.454368  0.578941   \n",
       "19  733979d75f59770d  0.345127  0.344127  0.336324  0.354399  0.396093   \n",
       "\n",
       "       pred5     pred6     pred7     pred8     pred9    pred10    pred11  \n",
       "0   0.542626  0.412257  0.599047  0.574789  0.556047  0.638238  0.325940  \n",
       "1   0.624701  0.707529  0.712458  0.750050  0.728954  0.758063  0.600674  \n",
       "2   0.429251  0.473934  0.511296  0.526621  0.501007  0.426838  0.514221  \n",
       "3   0.242358  0.253762  0.244287  0.234795  0.235337  0.316446  0.287925  \n",
       "4   0.000130  0.000105  0.000916  0.004200  0.002166  0.002237  0.112711  \n",
       "5   0.498857  0.466096  0.512878  0.480865  0.478713  0.579902  0.499533  \n",
       "6   0.340060  0.475942  0.475008  0.466500  0.447965  0.297359  0.459802  \n",
       "7   0.000004  0.000000  0.000000  0.000000  0.000015  0.000000  0.002243  \n",
       "8   0.238643  0.283237  0.326393  0.311302  0.320707  0.362896  0.253126  \n",
       "9   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
       "10  0.249689  0.263676  0.258595  0.202395  0.215285  0.203273  0.251305  \n",
       "11  0.251363  0.264081  0.248899  0.271611  0.268462  0.229380  0.273060  \n",
       "12  0.762709  0.728253  0.803228  0.794012  0.798070  0.787512  0.774945  \n",
       "13  0.791389  0.856201  0.851188  0.877980  0.826610  0.841518  0.875223  \n",
       "14  0.754177  0.733222  0.806421  0.791540  0.773154  0.769165  0.759415  \n",
       "15  0.290691  0.324725  0.334515  0.314764  0.311384  0.363792  0.288924  \n",
       "16  0.264921  0.210674  0.261868  0.243389  0.252132  0.237239  0.260456  \n",
       "17  0.000100  0.000041  0.000023  0.000133  0.000025  0.001013  0.003932  \n",
       "18  0.438615  0.485668  0.525461  0.530133  0.516070  0.530340  0.513335  \n",
       "19  0.349780  0.338782  0.299137  0.283303  0.279560  0.306789  0.398741  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd06486",
   "metadata": {
    "papermill": {
     "duration": 0.134257,
     "end_time": "2022-06-16T03:46:10.817268",
     "exception": false,
     "start_time": "2022-06-16T03:46:10.683011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1373.991915,
   "end_time": "2022-06-16T03:46:14.117416",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-16T03:23:20.125501",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
